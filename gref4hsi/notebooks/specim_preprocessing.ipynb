{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "D:/Specim/Missions/Lab_Calibrations/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import spectral as sp\n",
    "from spectral import envi\n",
    "import configparser\n",
    "import pandas as pd\n",
    "\n",
    "# To access the custom modules \n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from lib.specim_parsing_utils import Specim\n",
    "from scripts.modulate_config import prepend_data_dir_to_relative_paths\n",
    "\n",
    "MISSION_NAME_PREFIX = '2022-08-31-060000-Remoy-Specim' # I use UTC time to avoid any timezone BS\n",
    "\n",
    "DATE = '2022-08-31'\n",
    "MISSION_DIR = 'D:/Specim/Missions/2022-08-31_0800_HSI/'\n",
    "CAL_DIR = 'D:/Specim/Missions/Lab_Calibrations/'\n",
    "OUT_DIR = 'D:/HyperspectralDataAll/HI/' + MISSION_NAME_PREFIX + '/'\n",
    "\n",
    "ACTIVE_SENSOR_SPATIAL_PIXELS = 1024 # Constant for AFX10\n",
    "ACTIVE_SENSOR_SPECTRAL_PIXELS = 448 # Constant for AFX10\n",
    "\n",
    "print(CAL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data recorded for each Specim mission (in mission_dir) has the following necessary files for processing.\n",
    "```\n",
    "mission_dir\n",
    "├── capture\n",
    "    ├── <capture_name>.hdr\n",
    "    ├── <capture_name>.nav\n",
    "    └── <capture_name>.raw\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In addition the user must specify the following lab calibration directory (is the same for all missions):\n",
    "```\n",
    "lab_calibrations_dir/\n",
    "    FOV_AFX10_SN1120112_20210324_1b.txt\n",
    "    FOV_AFX10_SN1120112_20210324_2b.txt\n",
    "    Radiometric_1x1.cal\n",
    "    Radiometric_1x1.hdr\n",
    "    Radiometric_1x2.cal\n",
    "    Radiometric_1x2.hdr\n",
    "    Radiometric_2x1.cal\n",
    "    Radiometric_2x1.hdr\n",
    "    Radiometric_2x2.cal\n",
    "    Radiometric_2x2.hdr\n",
    "    Radiometric_4x1.cal\n",
    "    Radiometric_4x1.hdr\n",
    "    Radiometric_4x2.cal\n",
    "    Radiometric_4x2.hdr\n",
    "    Radiometric_8x1.cal\n",
    "    Radiometric_8x1.hdr\n",
    "    Radiometric_8x2.cal\n",
    "    Radiometric_8x2.hdr\n",
    "    wlcal1b_fwhm.wls\n",
    "    wlcal1b_fx.wls\n",
    "    wlcal2b_fwhm.wls\n",
    "    wlcal2b_fx.wls\n",
    "    wlcal4b_fwhm.wls\n",
    "    wlcal4b_fx.wls\n",
    "    wlcal8b_fwhm.wls\n",
    "    wlcal8b_fx.wls\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T\n",
    "config = configparser.ConfigParser()\n",
    "config.read(config_file)\n",
    "\n",
    "\n",
    "specim_object = Specim(mission_path=MISSION_DIR, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\haavasl\\AppData\\Local\\miniconda3\\envs\\hyperspectral_toolchain\\lib\\site-packages\\spectral\\io\\envi.py:175: UserWarning: Parameters with non-lowercase names encountered and converted to lowercase. To retain source file parameter name capitalization, set spectral.settings.envi_support_nonlowercase_params to True.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Reading envi format is achieved with spectral python.\n",
    "# This cell reads the main capture and finds relevant configs from *.hdr data\n",
    "\n",
    "\n",
    "\n",
    "PATTERN_ENVI = '*.hdr'\n",
    "CAPTURE_DIR = MISSION_DIR + '/capture/'\n",
    "\n",
    "search_path_envi = os.path.normpath(os.path.join(CAPTURE_DIR, PATTERN_ENVI))\n",
    "ENVI_HDR_FILE_PATH = glob.glob(search_path_envi)[0]\n",
    "\n",
    "spectral_image_obj = envi.open(ENVI_HDR_FILE_PATH)\n",
    "\n",
    "# Read all meta of interest (make explicit to developer and accessible with autocomplete)\n",
    "class Metadata:\n",
    "    pass\n",
    "\n",
    "metadata_obj = Metadata()\n",
    "metadata_obj.autodarkstartline = int(spectral_image_obj.metadata['autodarkstartline'])\n",
    "metadata_obj.n_lines = int(spectral_image_obj.metadata['lines'])\n",
    "metadata_obj.n_bands = int(spectral_image_obj.metadata['bands'])\n",
    "metadata_obj.n_pix = int(spectral_image_obj.metadata['samples'])\n",
    "metadata_obj.t_exp_ms = float(spectral_image_obj.metadata['tint'])\n",
    "metadata_obj.fps = float(spectral_image_obj.metadata['fps'])\n",
    "metadata_obj.description = spectral_image_obj.metadata['description']\n",
    "metadata_obj.file_type = spectral_image_obj.metadata['file type']\n",
    "metadata_obj.sensor_type = spectral_image_obj.metadata['sensor type']\n",
    "metadata_obj.acquisition_date = spectral_image_obj.metadata['acquisition date']\n",
    "metadata_obj.sensorid = spectral_image_obj.metadata['sensorid']\n",
    "metadata_obj.interleave = spectral_image_obj.metadata['interleave']\n",
    "metadata_obj.data_type = spectral_image_obj.metadata['data type']\n",
    "# USE FILES FROM LAB, not HEADER metadata_obj.wavelengths = np.array(spectral_image_obj.bands.centers)\n",
    "#NOT CORRECT!!!!!! This is spectral sampling distance: metadata_obj.fwhm = np.array(spectral_image_obj.bands.bandwidths)\n",
    "metadata_obj.binning_spatial = int(ACTIVE_SENSOR_SPATIAL_PIXELS/metadata_obj.n_pix)\n",
    "metadata_obj.binning_spectral = int(ACTIVE_SENSOR_SPECTRAL_PIXELS/metadata_obj.n_bands)\n",
    "\n",
    "# Binning solely determines which calibration files be used.\n",
    "\n",
    "# It holds a csv like format\n",
    "\n",
    "\n",
    "\n",
    "specim_object.metadata_obj = metadata_obj # Allow accesability for Specim Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the binning info, we can locate relevant calibration files, including 1) spectral, 2) geometric, 3) radiometric, and dark frame (from capture).\n",
    "\n",
    "We start with the spectral calibration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Reads spectral calibration based on binning into a wavelength array and a fwhm array\"\"\"\n",
    "\n",
    "# Comprehensive band info (center, fwhm) is found in \"CAL_DIR/wlcal<spectral binning>b_fwhm.wls\"\n",
    "PATTERN_BAND_INFO = '*'+ str(metadata_obj.binning_spectral) + 'b_fwhm.wls'\n",
    "# Linux-CLI search for file.\n",
    "search_path_bands = os.path.normpath(os.path.join(CAL_DIR, PATTERN_BAND_INFO))\n",
    "BAND_FILE_PATH = glob.glob(search_path_bands)[0]\n",
    "\n",
    "df_bands = pd.read_csv(BAND_FILE_PATH, header=None, sep = '\\s+')\n",
    "df_bands.columns = ['Wavelength_nm', 'FWHM_nm']\n",
    "\n",
    "specim_object.wavelengths = np.array(df_bands['Wavelength_nm'])\n",
    "specim_object.fwhm = np.array(df_bands['FWHM_nm'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will here go through the loading of Specim geometric camera model. The first step is to load the angular Field-of-View file (AFOV) from the manufacturer. Then boresight angles and lever arms can be set, if relevant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pixel-directions is found in \"CAL_DIR/FOV_****_<spatial binning>b.txt\" \n",
    "\n",
    "PATTERN_FOV = 'FOV*' + '_' +  str(metadata_obj.binning_spatial) + 'b.txt'\n",
    "\n",
    "# Search for fov file.\n",
    "search_path_fov = os.path.normpath(os.path.join(CAL_DIR, PATTERN_FOV))\n",
    "FOV_FILE_PATH = glob.glob(search_path_fov)[0]\n",
    "\n",
    "# Calculates a camera model based on FOV file \n",
    "specim_object.read_fov_file(fov_file_path=FOV_FILE_PATH)\n",
    "\n",
    "df_fov = pd.read_csv(FOV_FILE_PATH, header=None, sep = ',')\n",
    "\n",
    "df_fov.columns = ['Pixel_Nr', 'View_Angle_Deg', 'Unknown']\n",
    "\n",
    "specim_object.view_angles = np.array(df_fov['View_Angle_Deg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The addition of boresight angles can be done by editing tx, ty, tz, and rx, ry, rz in the \"OUTDIR/Input/Calib\". \n",
    "\n",
    "[tx, ty, tz] is the vector from HSI focal centre to reference origin (e.g. IMU) given in the reference frame. So if your BODY frame defines forward, right, down on the vehicle:\n",
    "\n",
    "[tx, ty, tz] = [1, 1, 1] means that HSI is 1 m behind, 1 m left of and 1 m above the IMU.\n",
    "\n",
    "Secondly, [rx, ry, rz] are Euler angles in radians with order 'ZYX'. If using another rotation convention, it's recommended to convert with scipy.spatial.Rotation. Example:\n",
    "\n",
    "    import scipy.spatial.Rotation as RotLib\n",
    "\n",
    "    # Let's say you have a rotation matrix transforming a vector from HSI frame to IMU frame\n",
    "    R_hsi_rgb = [[0, -1, 0],\n",
    "                 [1, 0, 0],\n",
    "                 [0, 0, 1]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"from scipy.spatial.transform import Rotation as RotLib\\n\\n# Let's say you have a rotation matrix transforming a vector from HSI frame to IMU frame\\n# This is the standard conversion from a Body frame to a camera frame where the x axis (pixel columns) are aligned with STARBOARD/right on the vehicle.\\nR_hsi_rgb = [[0,-1, 0],\\n             [1, 0, 0],\\n             [0, 0, 1]]\\n\\n# Quaternion (same rotation):\\nq_w = 1/np.sqrt(2)\\nq_x = 0\\nq_y = 0\\nq_z = 1/np.sqrt(2)\\n\\n# NB!! for the library, quaternions are represented in scalar-last (x, y, z, w) format, in contrast to the more used (w, x, y, z) format.\\nquat_hsi_rgb = np.array([q_x, q_y, q_z, q_w])\\n\\nr_zyx = RotLib.from_matrix(R_hsi_rgb).as_euler('ZYX', degrees=False)\\n\\nr_zyx = RotLib.from_quat(quat_hsi_rgb).as_euler('ZYX', degrees=False)\\n# And any other form of rotation description imaginable could be converted in this manner\\nr_x, r_y, r_z = np.flip(r_zyx)\\n\\nprint(r_z)\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from scipy.spatial.transform import Rotation as RotLib\n",
    "\n",
    "# Let's say you have a rotation matrix transforming a vector from HSI frame to IMU frame\n",
    "# This is the standard conversion from a Body frame to a camera frame where the x axis (pixel columns) are aligned with STARBOARD/right on the vehicle.\n",
    "R_hsi_rgb = [[0,-1, 0],\n",
    "             [1, 0, 0],\n",
    "             [0, 0, 1]]\n",
    "\n",
    "# Quaternion (same rotation):\n",
    "q_w = 1/np.sqrt(2)\n",
    "q_x = 0\n",
    "q_y = 0\n",
    "q_z = 1/np.sqrt(2)\n",
    "\n",
    "# NB!! for the library, quaternions are represented in scalar-last (x, y, z, w) format, in contrast to the more used (w, x, y, z) format.\n",
    "quat_hsi_rgb = np.array([q_x, q_y, q_z, q_w])\n",
    "\n",
    "r_zyx = RotLib.from_matrix(R_hsi_rgb).as_euler('ZYX', degrees=False)\n",
    "\n",
    "r_zyx = RotLib.from_quat(quat_hsi_rgb).as_euler('ZYX', degrees=False)\n",
    "# And any other form of rotation description imaginable could be converted in this manner\n",
    "r_x, r_y, r_z = np.flip(r_zyx)\n",
    "\n",
    "print(r_z)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Function added to remedy lacking byte-order entry in header files of radiometric calibration data\"\"\"\n",
    "def add_byte_order_to_envi_header(header_file_path, byte_order_value):\n",
    "    # Read the existing ENVI header\n",
    "    with open(header_file_path, 'r') as f:\n",
    "        header_lines = f.readlines()\n",
    "\n",
    "    # Look for the line where you want to add \"byte order\"\n",
    "    for i, line in enumerate(header_lines):\n",
    "        if line.startswith('byte order'):\n",
    "            # If it already exists, update the value\n",
    "            header_lines[i] = f'byte order = {byte_order_value}\\n'\n",
    "            break\n",
    "    else:\n",
    "        # If it doesn't exist, add it to the end of the header\n",
    "        header_lines.append(f'byte order = {byte_order_value}\\n')\n",
    "\n",
    "    # Save the updated header\n",
    "    with open(header_file_path, 'w') as f:\n",
    "        f.writelines(header_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to read in radiometric frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Extract radiometric frame from dedicated file\"\"\"\n",
    "\n",
    "PATTERN_ENVI_CAL = '*_' +str(metadata_obj.binning_spectral) + 'x' +  str(metadata_obj.binning_spatial) + '.hdr'\n",
    "\n",
    "search_path_envi_cal = os.path.normpath(os.path.join(CAL_DIR, PATTERN_ENVI_CAL))\n",
    "ENVI_CAL_HDR_FILE_PATH = glob.glob(search_path_envi_cal)[0]\n",
    "\n",
    "RAD_CAL_BYTE_ORDER = 0\n",
    "\n",
    "add_byte_order_to_envi_header(header_file_path=ENVI_CAL_HDR_FILE_PATH, byte_order_value=RAD_CAL_BYTE_ORDER)\n",
    "\n",
    "ENVI_CAL_IMAGE_FILE_PATH = ENVI_CAL_HDR_FILE_PATH.split('.')[0] + '.cal' # SPECTRAL does not expect this suffix by default\n",
    "\n",
    "# For some reason, the byte order\n",
    "\n",
    "radiometric_image_obj = envi.open(ENVI_CAL_HDR_FILE_PATH, image = ENVI_CAL_IMAGE_FILE_PATH)\n",
    "\n",
    "cal_n_lines = int(radiometric_image_obj.metadata['lines'])\n",
    "cal_n_bands = int(radiometric_image_obj.metadata['bands'])\n",
    "cal_n_pix = int(radiometric_image_obj.metadata['samples'])\n",
    "\n",
    "radiometric_frame = radiometric_image_obj[:,:,:].reshape((cal_n_pix, cal_n_bands))\n",
    "\n",
    "specim_object.radiometric_frame = radiometric_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is to load the darkframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"1) Crop the hyperspectral data according to the start-stop lines. 2) Write datacube to appropriate directory\"\"\"\n",
    "# To ensure that the plots actually do appear in this notebook:\n",
    "%matplotlib qt\n",
    "\n",
    "# Test plotting the data\n",
    "\n",
    "\n",
    "# Establish dark frame data\n",
    "data_dark = spectral_image_obj[metadata_obj.autodarkstartline:metadata_obj.n_lines, :, :]\n",
    "dark_frame = np.median(data_dark, axis = 0)\n",
    "\n",
    "#plt.plot(specim_object.band2Wavelength, np.mean(radiometric_frame, axis = 0))\n",
    "#data = spectral_image_obj.read_subimage(rows=np.arange(100), cols = np.arange(512))\n",
    "\n",
    "#spectral_image_obj.bands = np.arange(224)*2\n",
    "#data.bands = spectral_image_obj.bands.centers\n",
    "#spectral_image_obj.metadata['wavelength units'] = ['Nanometers']\n",
    "plt.imshow(radiometric_frame/radiometric_frame.max())\n",
    "#sp.imshow(radiometric, bands=(94,57,19), source=spectral_image_obj)\n",
    "\n",
    "specim_object.dark_frame = dark_frame\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The navigation data is given as messages is a *.nav file. Locate the file and parse it into a suitable format. From NAVIGEOPRO we'd get a sync file giving the pose per scan. Matching against such a file makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the starting/stopping lines\n",
    "import pandas as pd\n",
    "\n",
    "PATTERN_START_STOP = '*.txt'\n",
    "START_STOP_DIR = MISSION_DIR + '/start_stop_lines'\n",
    "\n",
    "search_path_lines_start_stop = os.path.normpath(os.path.join(START_STOP_DIR, PATTERN_START_STOP))\n",
    "LINES_START_STOP_FILE_PATH = glob.glob(search_path_lines_start_stop)[0]\n",
    "\n",
    "header = 0\n",
    "\n",
    "df_start_stop = pd.read_csv(filepath_or_buffer=LINES_START_STOP_FILE_PATH, header=header, sep=' ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now read the *.nav file\n",
    "NAV_PATTERN = '*.nav'\n",
    "\n",
    "search_path_nav = os.path.normpath(os.path.join(CAPTURE_DIR, NAV_PATTERN))\n",
    "nav_file_path = glob.glob(search_path_nav)[0]\n",
    "\n",
    "# Parse the position/orientation messages\n",
    "\n",
    "specim_object.read_nav_file(nav_file_path=nav_file_path, date = DATE)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the frame timestamps from sync data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1661925888.73\n"
     ]
    }
   ],
   "source": [
    "import pymap3d as pm\n",
    "df_imu = pd.DataFrame(specim_object.imu_data)\n",
    "df_gnss = pd.DataFrame(specim_object.gnss_data)\n",
    "df_sync_hsi = pd.DataFrame(specim_object.sync_data)\n",
    "# Define the time stamps of HSI frames\n",
    "\n",
    "\n",
    "# Let's consider this an interpolation problem. Every new sync means a new fps # frames:\n",
    "sync_frames = df_sync_hsi['HsiFrameNum']\n",
    "sync_times = df_sync_hsi['TimestampAbs']\n",
    "hsi_frames = np.arange(metadata_obj.autodarkstartline)\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "hsi_timestamps_total = interp1d(x = sync_frames, y= sync_times, fill_value = 'extrapolate')(x = hsi_frames)\n",
    "\n",
    "\n",
    "# Secondly, for ease, let us interpolate position data to imu time\n",
    "\n",
    "imu_time = df_imu['TimestampAbs']\n",
    "# Drop the specified column\n",
    "df_gnss = df_gnss.drop(columns=['TimestampClock'])\n",
    "# Interpolate each column based on 'new_time'\n",
    "interpolated_values = {\n",
    "    column: np.interp(imu_time, df_gnss['TimestampAbs'], df_gnss[column])\n",
    "    for column in df_gnss.columns if column != 'TimestampAbs'\n",
    "}\n",
    "# Create a new DataFrame with the interpolated values\n",
    "df_gnss_interpolated = pd.DataFrame({'time': imu_time, **interpolated_values})\n",
    "\n",
    "# The position defined in geodetic coordinates\n",
    "lat = np.array(df_gnss_interpolated['Lat']).reshape((-1,1))\n",
    "lon = np.array(df_gnss_interpolated['Lon']).reshape((-1,1))\n",
    "ellipsoid_height = np.array(df_gnss_interpolated['AltMSL'] + df_gnss_interpolated['AltGeoid']).reshape((-1,1))\n",
    "\n",
    "# defaults to WGS-84\n",
    "x,y,z = pm.geodetic2ecef(lat = lat, lon = lon, h = ellipsoid_height, deg=True)\n",
    "\n",
    "# Lastly, calculate the roll, pitch, yaw\n",
    "roll = np.array(df_imu['Roll']).reshape((-1,1))\n",
    "pitch = np.array(df_imu['Pitch']).reshape((-1,1))\n",
    "yaw = np.array(df_imu['Yaw']).reshape((-1,1))\n",
    "\n",
    "specim_object.eul_zyx = np.concatenate((roll, pitch, yaw), axis = 1)\n",
    "specim_object.position_ecef = np.concatenate((x,y,z), axis = 1)\n",
    "specim_object.nav_timestamp = imu_time\n",
    "specim_object.t_exp_ms = metadata_obj.t_exp_ms\n",
    "\n",
    "\n",
    "print(imu_time.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last preprocessing step involves writing the h5 files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a synchronization every second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the data for use in the geometric processing pipeline\n",
    "h5_dict_write = {'eul_zyx' : 'raw/nav/euler_angles',\n",
    "           'position_ecef' : 'raw/nav/position_ecef',\n",
    "           'nav_timestamp' : 'raw/nav/timestamp',\n",
    "           'radiance_cube': 'processed/radiance/radiance_cube',\n",
    "           't_exp_ms': 'processed/radiance/t_exp_ms',\n",
    "           'hsi_timestamps': 'processed/radiance/timestamp',\n",
    "           'view_angles': 'processed/radiance/calibration/geometric/view_angles',\n",
    "           'wavelengths' : 'processed/radiance/calibration/spectral/wavelengths',\n",
    "           'fwhm' : 'processed/radiance/calibration/spectral/fwhm',\n",
    "           'dark_frame' : 'processed/radiance/calibration/dark_frame',\n",
    "           'radiometric_frame' : 'processed/radiance/calibration/radiometric_frame'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to write all the data to a h5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\"\"\"Reader for the h5 file format in UHI context. The user provides h5 hierarchy paths as values and keys are the names given to the attributes \"\"\"\n",
    "def specim_object_2_h5_file(h5_filename, h5_tree_dict, specim_object):\n",
    "    with h5py.File(h5_filename, 'w', libver='latest') as f:\n",
    "        for attribute_name, h5_hierarchy_item_path in h5_tree_dict.items():\n",
    "            print(attribute_name)\n",
    "            dset = f.create_dataset(name=h5_hierarchy_item_path, \n",
    "                                            data = getattr(specim_object, attribute_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n",
      "eul_zyx\n",
      "position_ecef\n",
      "nav_timestamp\n",
      "radiance_cube\n",
      "t_exp_ms\n",
      "hsi_timestamps\n",
      "view_angles\n",
      "wavelengths\n",
      "fwhm\n",
      "dark_frame\n",
      "radiometric_frame\n"
     ]
    }
   ],
   "source": [
    "# Define h5 file name\n",
    "h5_folder = OUT_DIR + 'Input/H5/'\n",
    "# Every 1000 lines take up 0.85 GB. Therefore it could make sense to partition things that are larger than 2000 lines\n",
    "TRANSECT_CHUNK_SIZE = 2000\n",
    "\n",
    "n_transects = df_start_stop.shape[0]\n",
    "for transect_number in range(n_transects):\n",
    "    start_line = df_start_stop['line_start'][transect_number]\n",
    "    stop_line = df_start_stop['line_stop'][transect_number]\n",
    "\n",
    "    n_chunks = int(np.ceil((stop_line-start_line)/TRANSECT_CHUNK_SIZE))\n",
    "\n",
    "    \n",
    "    for chunk_number in range(n_chunks):\n",
    "        chunk_start_idx = start_line + TRANSECT_CHUNK_SIZE*chunk_number\n",
    "\n",
    "        if chunk_number == n_chunks-1:\n",
    "            chunk_stop_idx = stop_line\n",
    "        else:\n",
    "            chunk_stop_idx = chunk_start_idx + TRANSECT_CHUNK_SIZE\n",
    "\n",
    "\n",
    "\n",
    "        data_cube = spectral_image_obj[chunk_start_idx:chunk_stop_idx, :, :]\n",
    "        # Calibration equation\n",
    "        specim_object.radiance_cube = (data_cube - dark_frame)*radiometric_frame/(metadata_obj.t_exp_ms/1000)\n",
    "        specim_object.hsi_timestamps = hsi_timestamps_total[chunk_start_idx:chunk_stop_idx]\n",
    "\n",
    "        # Possible to name files with <PREFIX>_<time_start>_<Transect#>_<Chunk#>.h5\n",
    "        h5_filename = h5_folder + MISSION_NAME_PREFIX + '_transectnr_' + str(int(transect_number)) + '_chunknr_' + str(int(chunk_number)) + '.h5'\n",
    "\n",
    "        specim_object_2_h5_file(h5_filename=h5_filename, h5_tree_dict=h5_dict_write, specim_object=specim_object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
